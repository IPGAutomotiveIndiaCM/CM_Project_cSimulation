pipeline {
    agent any
    environment {
        IPGHOME = "/opt/ipg/"
        S3_BUCKET_NAME = 'ipgindia'
        TESTRUN_PATH = '/var/lib/jenkins/workspace/cSimulation/Data/TestRun'
        RESULT_FILE_S3_URL='s3://ipgindia/auto-pilot/Results/'
    }

    stages {
        stage('Build Code') {
            steps {
                withCredentials([usernamePassword(credentialsId: 'cSimulation', usernameVariable: 'GIT_USERNAME', passwordVariable: 'GIT_PASSWORD')]) {
                    checkout scm
                    sh '''
                    git clean -fd
                    git checkout master
                    git pull origin master
                    cd src
                    make clean
                    make
                    '''
                }
            }
        }

        stage('Upload to S3') {
            steps {
                script {
                    // Upload the TestRun directory to S3
                    sh """
                        aws s3 cp ${TESTRUN_PATH} s3://${S3_BUCKET_NAME}/auto-pilot/TestRun/ --recursive
                    """
                }
            }
        }
        stage('aws batch sumit') {
            steps {
                script {
                    // Upload the TestRun directory to S3
def submitResult = sh(script: """
                aws batch submit-job --job-name demo_job_3 --job-queue demo_ipg --job-definition demo_ipg_job_def --array-properties size=3 --region us-east-2 --container-overrides '{
                    "vcpus": 1,
                    "memory": 1000,
                    "environment": [
                        {"name": "TESTRUN_FILE_S3_URL", "value": "s3://ipgindia/auto-pilot/TestRun/"},
                        {"name": "RESULT_FILE_S3_URL", "value": "s3://ipgindia/auto-pilot/Results/"},
                        {"name": "BATCH_JOB_SIZE", "value": "1"},
                        {"name": "CONSECUTIVE_JOBS", "value": "1"}
                    ]
                }'
            """, returnStdout: true).trim()

            // Extract the job ID from the response
            def jobId = submitResult =~ /"jobId": "(.*?)"/
            jobId = jobId[0][1]

            // Save the job ID for the next stage
            currentBuild.description = "Job ID: ${jobId}"
            echo "Submitted AWS Batch job with Job ID: ${jobId}"
                }
            }
        }
        stage('Wait for AWS Batch job to finish') {
    steps {
        script {
            def jobId = currentBuild.description.split(":")[1].trim()

            // Check job status
            def status = sh(script: """
                aws batch describe-jobs --jobs ${jobId} --region us-east-2 --query 'jobs[0].status' --output text
            """, returnStdout: true).trim()

            // Wait for the job to complete
            while (status != 'SUCCEEDED' && status != 'FAILED') {
                echo "Waiting for job to complete... Current status: ${status}"
                sleep(60)  // Sleep for 1 minute before checking again
                status = sh(script: """
                    aws batch describe-jobs --jobs ${jobId} --region us-east-2 --query 'jobs[0].status' --output text
                """, returnStdout: true).trim()
            }

            if (status == 'FAILED') {
                error("AWS Batch job failed!")
            } else {
                echo "AWS Batch job completed successfully."
            }
        }
    }
}
      stage('Result to jenkins') {
            steps {
                script {
                    // Upload the TestRun directory to S3
                    sh """
                       aws s3 cp ${RESULT_FILE_S3_URL} /var/lib/jenkins/workspace/cSimulation/SimOutput --recursive --exclude "*" --include "*.erg"
                       aws s3 cp ${RESULT_FILE_S3_URL} /var/lib/jenkins/workspace/cSimulation/SimOutput --recursive --exclude "*" --include "*.erg.info"
                        
                    """
                }
            }
        }
    stage('Rport to s3 ') {
            steps {
                script {
                    // Upload the result directory to S3
                    sh """
                       aws s3 cp ${RESULT_FILE_S3_URL} /var/lib/jenkins/workspace/cSimulation/SimOutput --recursive --exclude "*" --include "*.erg"
                       aws s3 cp ${RESULT_FILE_S3_URL} /var/lib/jenkins/workspace/cSimulation/SimOutput --recursive --exclude "*" --include "*.erg.info"
                       
                    """
                }
            }
        }

 
       
    }

    post {
        success {
            echo 'Build and upload to S3 completed successfully!'
        }
        failure {
            echo 'Build failed. Check the logs.'
        }
    }
}
